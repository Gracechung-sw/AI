{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit_generator_flow_from\n",
    ": 4. fit_generator에서는 flow라는 것으로 이미지를 이미 로드 한 다음에 DataGenerator을 사용했는데\n",
    "이번 5. fit_generator_flow from에서는 폴더별로 담겨있는 이미지를 한 번에 로드 하는 방법에 대해서 알아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9', '0', '7', '6', '1', '8', '4', '3', '2', '5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/mnist_png/training/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 폴더별로 labeling 되어 있는 경우는, 담겨있는 이미지는 현재 하는 방법을 이용하는게 매우 유용하다. \n",
    "\n",
    "cf) 'for github/인공지능_딥러닝_dataset'에 있는 또 다른 예제인 'cifar'같은 경우, 폴더별이 아니라 파일명에 label이 있기 때문에 이 방법을 쓸 수 없고, 복잡해 진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/mnist_png/training'\n",
    "test_dir ='/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/mnist_png/testing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size =32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.7\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagenerator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    width_shift_range = 0.3,\n",
    "    zoom_range = 0.7,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_datagenerator = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#train 이미지 generator 생성\n",
    "\n",
    "#flow시키는 generator 생성\n",
    "#폴더별로 있으니까\n",
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "    train_dir, #앞에서 한 train_dir = '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/mnist_png/training'\n",
    "    target_size = input_shape[:2], #input_shape = (28, 28, 1)에서 채널빼고 (28, 28)만)\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'grayscale', \n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#test 이미지 generator 생성\n",
    "validation_generator = test_datagenerator.flow_from_directory(\n",
    "    test_dir, #앞에서 한 train_dir = '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/mnist_png/training'\n",
    "    target_size = input_shape[:2], #input_shape = (28, 28, 1)에서 채널빼고 (28, 28)만)\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'grayscale', \n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "#이건 이전에 많이 한 것대로\n",
    "inputs = layers.Input(input_shape)\n",
    "net = layers.Conv2D(32, 3, padding = 'SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, 3, padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size = 2)(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, 3, padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, 3, padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size = 2)(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = net, name = 'Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compile해주기\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate), #Optimization\n",
    "             loss = 'categorical_crossentropy', #Loss function\n",
    "             metrics = ['accuracy']) #Metrics/Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "model.fit_generator(\n",
    "    generator,\n",
    "    steps_per_epoch=None,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    callbacks=None,\n",
    "    validation_data=None,\n",
    "    validation_steps=None,\n",
    "    validation_freq=1,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train_generator), \n",
    "    epochs = num_epochs,\n",
    "    validation_data =validation_generator, \n",
    "    validation_steps = len(validation_generator))#steps_per_epoch : 한 epoch에 몇 개의 묶음의 이미지(batch)가 epoch에 돌아갈지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

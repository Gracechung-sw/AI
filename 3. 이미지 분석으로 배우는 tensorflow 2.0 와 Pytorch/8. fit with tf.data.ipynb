{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. fit with tf.data\n",
    "이전 시간 (7. tf.data 사용하여 image & make batch.ipynb)에서 한 tf.data를 fit.generator에 넣어보는 작업 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 설정 (Build model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data PreProgress \n",
    "(data generator사용하지 않는) 이전 시간에 했던 과정 반복 + 더 이어서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/*.png')\n",
    "test_paths = glob('/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/32270_deer.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/21851_cat.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/48309_deer.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/33547_truck.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/45202_automobile.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/2789_bird.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/24517_horse.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/15193_frog.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/10817_ship.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/49897_ship.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/2598_cat.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/7195_horse.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/6171_deer.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/2586_horse.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/8372_automobile.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/3541_bird.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/332_cat.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/4811_bird.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/2255_automobile.png',\n",
       " '/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/7418_ship.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image, label 함께 가져오는 것도 이전 시간에 했던 과정 반복\n",
    "#일단 train에서 첫번째꺼 하나만 해보기\n",
    "#path = train_paths[0]\n",
    "#path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    fname\n",
    "    label_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    return label_name\n",
    "\n",
    "classes = [get_class_name(path) for path in train_paths]\n",
    "classes = tf.unique(classes)\n",
    "\n",
    "\n",
    "def onehot_encoding(label_name):\n",
    "    classes = get_class_name(path)\n",
    "    onehot = tf.cast(label_name == classes, tf.uint8)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    #read image\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    \n",
    "    #normalization\n",
    "    image = tf.cast(image,tf.float32)/255.\n",
    "    \n",
    "    #read label\n",
    "    class_name = get_class_name(path)\n",
    "    label = onehot_encoding(class_name)\n",
    "    \n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지를 변환시키는 image preprocess\n",
    "\n",
    "#image, label = read_dataset(path)\n",
    "#image.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    #tf.image. 뒤에 제공되는 함수는 매우 많다.\n",
    "\n",
    "    #이 중 random_flip_left_right 을 한 번 해보면, \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 함수 실행 한 것 시각화 해서 잘 만 들어 졌는지 확인\n",
    "transformed_image, label = image_preprocess(image, label)\n",
    "transformed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original image')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Transformed image')\n",
    "plt.imshow(transformed_image)\n",
    "\n",
    "plt.show() #좌우 반전이 잘 된 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset 처리\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(read_dataset) #image 와 label이 함께 담김\n",
    "\n",
    "#이때 data generator를 사용하기 위해선 이미지에 변화를 주고 해야 하니transform image가 \n",
    "train_dataset = train_dataset.map(image_preprocess)\n",
    "\n",
    "#batch\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "#shuffle\n",
    "train_dataset = train_dataset.shuffle(buffer_size = len(train_paths))\n",
    "\n",
    "#repeat : 계속 돌아가게 하기 위해서\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset 처리\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(read_dataset)\n",
    "test_dataset = test_dataset.map(image_preprocess)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = len(test_paths))\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training\n",
    "앞에서 이미지 preprocessing 다 했으니 이제 본격적인 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch = len(train_paths)//batch_size, #len(train_dataset)하면 에러남\n",
    "    validation_data = test_dataset,\n",
    "    validation_steps = len(test_paths)//batch_size,\n",
    "    epochs = num_epochs \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

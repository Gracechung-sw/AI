{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Callbacks\n",
    "callbacks : 학습 도중에 어떤 이벤트를 일으키는 것\n",
    "지금까지 실습한 부분도 모두 필요하므로 앞에 지금까지 한 내용을 적어주고, \n",
    "callbacks 실습을 시작한다. \n",
    "\n",
    "##이번 시간에는 callbacks 중에 tensorboard를 여는 방법을 알아보도록 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모듈 불러오기\n",
    "tensorflow 2.0에서 jupyter에서 바로 tensorboard를 실행 할 수 있게 되었다. \n",
    "> using   %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.7\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding = 'SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size = (2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3,3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size = (2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs =inputs, outputs = net, name = 'Basic_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate), #Optimization\n",
    "             loss = 'sparse_categorical_crossentropy', #Loss Function\n",
    "             metrics = ['accuracy'])#Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/train/*.png')\n",
    "test_paths = glob('/Users/jeonghyeonjeong/for github/인공지능_딥러닝_dataset/cifar/test/*.png')\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label의 class 보기\n",
    "#get_class_name : 파일 명으로 부터 label추출하는 함수\n",
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 함수를 사용해서 모든 파일의 label 추출 한 후 unique한 것만 뽑아서 총 class가 뭔지, 몇 개인지 보기\n",
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일마다 label을 추출하고, => 그 label을 one hot encoding까지 마무리하기\n",
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot) #그렇게 onehot해줘서 1이 된 곳의 번호를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image와 label을 함께 나타내기\n",
    "def load_image_label(path):\n",
    "    \n",
    "    #해당 파일의 이미지 불러고오기\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    \n",
    "    #normailzation\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    \n",
    "    #해당 이미지의 label불러오기\n",
    "    label = get_label(path)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 변형 해주기\n",
    "\n",
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 2, 23, 14, 14, 51, 50280)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/20200223-141452'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join('logs', datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "logdir\n",
    "        #앞에서 from datetime import datetime : 현재시간 사용할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks 불러오기\n",
    "#: tf.keras.callbacks. 하고 tap 누르면 다양한 게 있는데 여기서는 TensorBoard를 써보도록 한다. \n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = logdir, \n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    histogram_freq=1\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/bin/tensorboard\", line 10, in <module>\n",
       "    sys.exit(run_main())\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages/tensorboard/main.py\", line 58, in run_main\n",
       "    default.get_plugins() + default.get_dynamic_plugins(),\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages/tensorboard/default.py\", line 110, in get_dynamic_plugins\n",
       "    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages/tensorboard/default.py\", line 110, in <listcomp>\n",
       "    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2442, in load\n",
       "    self.require(*args, **kwargs)\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2465, in require\n",
       "    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n",
       "  File \"/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
       "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
       "pkg_resources.VersionConflict: (grpcio 1.16.1 (/Users/jeonghyeonjeong/anaconda3/lib/python3.6/site-packages), Requirement.parse('grpcio>=1.24.3'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " %tensorboard --logdir logs --port 8008\n",
    "\n",
    "#이렇게 하면 여기서 tensorboard 실행 할 수 있고, 여기서 바로 볼 수 있다.\n",
    "#일단 나는 ERROR: Failed to launch TensorBoard (exited with 1) 에러가떠서 안되는데 일단 밑에서 학습 먼저 진행하고, 이를 나중에 해결 해 보도록한다\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 823/1562 [==============>...............] - ETA: 7:12 - loss: 2.0496 - accuracy: 0.2192"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths)//batch_size\n",
    "validation_steps = len(test_paths)//batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "    callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

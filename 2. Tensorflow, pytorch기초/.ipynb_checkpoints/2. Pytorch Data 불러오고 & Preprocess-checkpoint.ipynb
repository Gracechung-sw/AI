{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pytorch Data Preprocess\n",
    ": pytorch로 MNIST 불러오고 불러온 데이터 시각화해서 확인해보기\n",
    "\n",
    "=> **torch.utils.data.DataLoader** 의 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader 부르기\n",
    ": pytorch 는 utils.data에 있는 DataLoader를 불러 model에 넣는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader 불러오기\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset/', #저장 경로\n",
    "                    train = True, #train용으로 만들 거다. \n",
    "                    download = True, #없으면 download해라\n",
    "                    transform = transforms.Compose([ #transform 해주는 옵션들\n",
    "                                                   transforms.ToTensor(), \n",
    "                                                   transforms.Normalize(mean = (0.5,), std = (0.5,))\n",
    "                                                ])), \n",
    "    batch_size = batch_size, \n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loader 불러오기\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset/', #저장 경로\n",
    "                    train = False, #train용이 안니다. \n",
    "                    download = True, #없으면 download해라\n",
    "                    transform = transforms.Compose([ #transform 해주는 옵션들\n",
    "                                                   transforms.ToTensor(), \n",
    "                                                   transforms.Normalize(mean = (0.5,), std = (0.5,))\n",
    "                                                ])), \n",
    "    batch_size = test_batch_size, \n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 번째 iteration에서 나오는 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape \n",
    "#tesorflow에서는 [batch_size, height, width, channel]이었는데 \n",
    "#pytorch에서는 [batch_size, channel, height, width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이미지 하나(images[0]) 시각화 할 때, height, width만 남길려고 .squeeze\n",
    "torch_image = torch.squeeze(images[0])\n",
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이미지와 label모두 numpy화 해주고\n",
    "torch_image = torch_image.numpy()\n",
    "torch_label = labels[0].numpy()\n",
    "torch_image.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#시각화\n",
    "plt.title(torch_label)\n",
    "plt.imshow(torch_image, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow는 방법이 너무 많은 반면에, \n",
    "\n",
    "pytorch는 이럴 땐 이걸 써! 라고 딱 정해준다. \n",
    "\n",
    "지금도 **data를 불러올 땐 torch.utils.data.DataLoader 써 라고 딱 정해져있다 .**\n",
    "\n",
    "pytorch는 이런점이 좋다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
